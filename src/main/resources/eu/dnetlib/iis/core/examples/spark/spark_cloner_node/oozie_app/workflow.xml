<?xml version="1.0"?>

<!-- 

    This is a spark equivalent of /eu/dnetlib/core/examples/javamapreduce/cloner 
    
-->

<workflow-app xmlns="uri:oozie:workflow:0.5" name="spark_avro_cloner (core-examples)">
    
    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapred.job.queue.name</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
        </configuration>
    </global>
    
    
    <start to="data_producer" />

    <action name="data_producer">
        <java>
            <!-- The data generated by this node is deleted in this section -->
            <prepare>
                <delete path="${nameNode}${workingDir}/data_producer" />
                <mkdir path="${nameNode}${workingDir}/data_producer" />
            </prepare>

            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>

            <arg>eu.dnetlib.iis.core.examples.java.SampleDataProducer</arg>

            <arg>-Operson=${workingDir}/data_producer/person</arg>

            <arg>-Odocument=${workingDir}/data_producer/document</arg>

        </java>
        <ok to="spark_avro_cloner" />
        <error to="fail" />
    </action>
    
    
     <action name="spark_avro_cloner">
    
        <spark xmlns="uri:oozie:spark-action:0.1">
            
            
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            
            <prepare>
                <delete path="${nameNode}${workingDir}/spark_cloner_node" />
                <mkdir path="${nameNode}${workingDir}/spark_cloner_node" />
            </prepare>
            
            <master>yarn-cluster</master>
        
            <mode>cluster</mode>
        
            <name>spark_avro_cloner</name>
        
            <class>eu.dnetlib.iis.core.examples.spark.SparkAvroCloner</class>
            
            <jar>${wf:conf('oozie.wf.application.path')}/lib/iis-wf-core-examples-${projectVersion}.jar</jar>
            
            <arg>-inputAvroPath = ${workingDir}/data_producer/person</arg>
            
            <arg>-avroSchemaClass = eu.dnetlib.iis.core.examples.schemas.documentandauthor.Person</arg>
            
            <arg>-outputAvroPath = ${workingDir}/spark_cloner_node/person</arg>
            
            <arg>-numberOfCopies = 2</arg>
            
            
        
        </spark>
    
        <ok to="simple_java_cloner" />
    
        <error to="fail" />
    
     </action>
    
    
     <action name="simple_java_cloner">
        <java>
            <!-- The data generated by this node is deleted in this section -->
            <prepare>
                <delete path="${nameNode}${workingDir}/simple_java_cloner" />
                <mkdir path="${nameNode}${workingDir}/simple_java_cloner" />
            </prepare>
            
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            
            <arg>eu.dnetlib.iis.core.examples.java.PersonCloner</arg>
        
            <arg>-Iperson=${workingDir}/spark_cloner_node/person</arg>
        
            <arg>-Operson=${workingDir}/simple_java_cloner/person</arg>
        
        </java>
        <ok to="end" />
        <error to="fail" />
    </action>
  
    <kill name="fail">
        <message>Unfortunately, the process failed -- error message:
            [${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>
    <end name="end" />
</workflow-app>

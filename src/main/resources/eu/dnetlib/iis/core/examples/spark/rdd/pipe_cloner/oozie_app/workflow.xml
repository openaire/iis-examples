<?xml version="1.0"?>
<workflow-app xmlns="uri:oozie:workflow:0.5" name="spark_pipe_cloner (core-examples)">

    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
        <configuration>
            <property>
                <name>mapreduce.job.queuename</name>
                <value>${queueName}</value>
            </property>
            <property>
                <name>oozie.launcher.mapred.job.queue.name</name>
                <value>${oozieLauncherQueueName}</value>
            </property>
            <property>
                <name>oozie.action.sharelib.for.spark</name>
                <value>spark2</value>
            </property>
        </configuration>
    </global>

    <start to="producer"/>

    <action name="producer">
        <java>
            <prepare>
                <delete path="${nameNode}${workingDir}/producer"/>
                <mkdir path="${nameNode}${workingDir}/producer"/>
            </prepare>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.core.examples.java.SampleDataProducer</arg>
            <arg>-Operson=${workingDir}/producer/person</arg>
            <arg>-Odocument=${workingDir}/producer/document</arg>
        </java>
        <ok to="spark_pipe_cloner"/>
        <error to="fail"/>
    </action>

    <action name="spark_pipe_cloner">
        <spark xmlns="uri:oozie:spark-action:0.2">
            <prepare>
                <delete path="${nameNode}${workingDir}/cloner"/>
                <mkdir path="${nameNode}${workingDir}/cloner"/>
            </prepare>
            <master>yarn-cluster</master>
            <mode>cluster</mode>
            <name>spark_pipe_cloner</name>
            <class>eu.dnetlib.iis.core.examples.spark.rdd.SparkPipeMapReduce</class>
            <jar>${wf:conf('oozie.wf.application.path')}/lib/iis-wf-core-examples-${projectVersion}.jar</jar>
            <spark-opts>
                --conf spark.extraListeners="com.cloudera.spark.lineage.NavigatorAppListener"
                --conf spark.sql.queryExecutionListeners="com.cloudera.spark.lineage.NavigatorQueryListener"
                --conf spark.yarn.historyServer.address="http://iis-ci-test.ocean.icm.edu.pl:18089"
                --conf spark.eventLog.dir="hdfs://iis-ci-test.ocean.icm.edu.pl:8020/user/spark/spark2ApplicationHistory"
            </spark-opts>
            <arg>-inputAvroPath = ${workingDir}/producer/person</arg>
            <arg>-inputAvroSchemaClass = eu.dnetlib.iis.core.examples.schemas.documentandauthor.Person</arg>
            <arg>-outputAvroPath = ${workingDir}/cloner/person</arg>
            <arg>-outputAvroSchemaClass = eu.dnetlib.iis.core.examples.schemas.documentandauthor.Person</arg>
            <arg>-mapperScript = ${wf:conf('oozie.wf.application.path')}/scripts/cloner.py</arg>
            <arg>-mapperScriptArgs = --copies 3</arg>
            <arg>-reducerScript = ${wf:conf('oozie.wf.application.path')}/scripts/cloner.py</arg>
            <arg>-reducerScriptArgs = --copies 2</arg>
        </spark>
        <ok to="consumer"/>
        <error to="fail"/>
    </action>

    <action name="consumer">
        <java>
            <main-class>eu.dnetlib.iis.common.java.ProcessWrapper</main-class>
            <arg>eu.dnetlib.iis.core.examples.java.PersonTestingConsumer</arg>
            <arg>-Iperson=${workingDir}/cloner/person</arg>
            <arg>-Pexpected_copies=6</arg>
        </java>
        <ok to="end"/>
        <error to="fail"/>
    </action>

    <kill name="fail">
        <message>Unfortunately, the process failed -- error message:
            [${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>

    <end name="end"/>

</workflow-app>


